[NeMo W 2025-04-14 15:59:47 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 15:59:48 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 15:59:49 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 15:59:49 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 15:59:49 finetune:97] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 15:59:49 finetune:98] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: true
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 15:59:49 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 15:59:49 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f620af5df40> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f620af5df40>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 15:59:49 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 15:59:49 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 15:59:49 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 15:59:49 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:01:32 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:01:33 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:01:34 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:01:34 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:01:34 finetune:97] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:01:34 finetune:98] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: true
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:01:34 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:01:34 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f5535a92ee0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f5535a92ee0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:01:34 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:01:34 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:01:34 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:01:34 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:02:38 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:02:39 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:02:39 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:02:40 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:02:40 finetune:97] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:02:40 finetune:98] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: true
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: false
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:02:40 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:02:40 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f824aef9f10> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f824aef9f10>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:02:40 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:02:40 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:02:40 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:02:40 exp_manager:660] TensorboardLogger has been set up
[NeMo I 2025-04-14 16:02:40 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:02:40 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:02:40 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:02:40 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:02:40 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:02:40 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:02:40 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:02:40 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:02:40 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:02:40 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:02:40 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:02:40 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:02:40 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:02:40 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:02:40 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:04:11 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:04:12 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:04:13 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:04:13 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:04:13 finetune:97] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:04:13 finetune:98] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: true
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: regex
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:04:13 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:04:13 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f563002daf0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f563002daf0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:04:13 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:04:13 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:04:13 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:04:13 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:04:51 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:04:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:04:52 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:04:52 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:04:52 finetune:97] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:04:52 finetune:98] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: true
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: regex
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:04:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:04:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7fc37696e070> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7fc37696e070>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:04:52 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:04:52 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:04:52 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:04:53 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:09:03 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:09:04 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:09:04 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:09:04 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:09:04 finetune:98] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:09:04 finetune:99] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: true
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: regex
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:09:04 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:09:04 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f570e96cfa0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f570e96cfa0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:09:04 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:09:04 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:09:04 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:09:04 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:11:54 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:11:55 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:11:56 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:11:56 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:11:56 finetune:98] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:11:56 finetune:99] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: true
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: regex
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:11:56 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:11:56 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f73c59a0160> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f73c59a0160>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:11:56 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:11:56 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:11:56 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:11:56 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:24:04 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:24:05 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:24:06 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:24:06 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:24:06 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:24:06 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: regex
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:24:06 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:24:06 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f1b44d7d0d0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f1b44d7d0d0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:24:06 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:24:06 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:24:06 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:24:06 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:24:06 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:24:06 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:24:06 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:24:06 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:24:06 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:24:06 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:24:06 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:24:06 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:24:06 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:24:06 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:24:06 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:24:06 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:24:06 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:24:06 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:24:06 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:24:06 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:24:06 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:24:06 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo W 2025-04-14 16:25:37 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:25:38 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:25:39 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:25:39 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:25:39 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:25:39 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: regex
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:25:39 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:25:39 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f60ecd52160> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f60ecd52160>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:25:39 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:25:39 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:25:39 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:25:39 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:25:39 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:25:39 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:25:39 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:25:39 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:25:39 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:25:39 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:25:39 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:25:39 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:25:39 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:25:39 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:25:39 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:25:39 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:25:39 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:25:39 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:25:39 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:25:39 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:25:39 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:25:39 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:25:39 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:25:39 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:25:39 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:25:39 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:25:39 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:25:39 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:25:39 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:30:50 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:30:51 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:30:52 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:30:52 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:30:52 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:30:52 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:30:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:30:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7fa63ab92850> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7fa63ab92850>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:30:52 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:30:52 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:30:52 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:30:52 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:30:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:30:52 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:30:52 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:30:52 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:30:52 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:30:52 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:30:52 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:30:52 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:30:52 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:30:52 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:30:52 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:30:52 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:30:52 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:30:52 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:30:52 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:30:52 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:30:52 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:30:52 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:30:52 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:30:52 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:30:52 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:30:52 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:30:52 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:30:52 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:30:52 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:30:52 finetune:105] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:107] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:30:52 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:30:52 finetune:111] ************** Starting Training ***********
[NeMo W 2025-04-14 16:30:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:30:53 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo W 2025-04-14 16:33:20 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:33:21 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:33:22 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:33:22 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:33:22 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:33:22 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train.csv
          val: zinc_data_finetune_valid.csv
          test: ''
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:33:22 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:33:22 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7efe1fc64ac0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7efe1fc64ac0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:33:22 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:33:22 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:33:22 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:33:22 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:33:22 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:33:22 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:33:22 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:33:22 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:33:22 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:33:22 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:33:22 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:33:22 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:33:22 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:33:22 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:33:22 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:33:22 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:33:22 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:33:22 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:33:22 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:33:22 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:33:22 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:33:22 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:33:22 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:33:22 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:33:22 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:33:22 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:33:22 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:33:22 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:33:22 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:33:23 finetune:105] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:107] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:33:23 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:33:23 finetune:111] ************** Starting Training ***********
[NeMo W 2025-04-14 16:33:23 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:33:23 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:33:23 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo W 2025-04-14 16:34:14 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:34:15 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:34:15 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:34:15 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:34:15 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:34:15 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: ''
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:34:15 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:34:15 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f999e71db50> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f999e71db50>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:34:15 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:34:15 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:34:15 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:34:15 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:34:15 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:34:15 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:34:15 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:34:16 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:34:16 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:34:16 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:34:16 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:34:16 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:34:16 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:34:16 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:34:16 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:34:16 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:34:16 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:34:16 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:34:16 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:34:16 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:34:16 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:34:16 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:34:16 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:34:16 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:34:16 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:34:16 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:34:16 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:34:16 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:34:16 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:34:16 finetune:105] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:107] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:34:16 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:34:16 finetune:111] ************** Starting Training ***********
[NeMo W 2025-04-14 16:34:16 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:34:16 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:34:16 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo W 2025-04-14 16:35:16 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:35:17 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:35:17 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:35:18 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:35:18 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:35:18 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: ''
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:35:18 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:35:18 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f13d1aefbb0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f13d1aefbb0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:35:18 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:35:18 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:35:18 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:35:18 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:35:18 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:35:18 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:35:18 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:35:18 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:35:18 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:35:18 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:35:18 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:35:18 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:35:18 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:35:18 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:35:18 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:35:18 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:35:18 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:35:18 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:35:18 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:35:18 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:35:18 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:35:18 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:35:18 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:35:18 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:35:18 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:35:18 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:35:18 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:35:18 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:35:18 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:35:18 finetune:105] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:107] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:35:18 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:18 finetune:111] ************** Starting Training ***********
[NeMo W 2025-04-14 16:35:18 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:35:18 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:35:18 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 16:35:18 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 16:35:18 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:35:18 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:35:19 text_memmap_dataset:215] Building idx file = /workspace/zinc_example_data/train/zinc_data_finetune_train.csv.idx
[NeMo I 2025-04-14 16:35:19 text_memmap_dataset:250] Time building 1 / 1 mem-mapped files: 0:00:00.261405
[NeMo I 2025-04-14 16:35:19 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:35:19 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 16:35:19 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000379
[NeMo I 2025-04-14 16:35:19 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:35:19 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo W 2025-04-14 16:35:40 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:35:41 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:35:41 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:35:42 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:35:42 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:35:42 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: ''
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:35:42 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:35:42 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7fd3a6258a90> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7fd3a6258a90>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:35:42 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:35:42 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:35:42 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:35:42 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:35:42 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:35:42 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:35:42 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:35:42 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:35:42 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:35:42 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:35:42 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:35:42 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:35:42 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:35:42 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:35:42 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:35:42 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:35:42 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:35:42 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:35:42 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:35:42 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:35:42 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:35:42 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:35:42 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:35:42 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:35:42 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:35:42 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:35:42 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:35:42 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:35:42 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:35:42 finetune:105] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:107] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:35:42 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:35:42 finetune:111] ************** Starting Training ***********
[NeMo W 2025-04-14 16:35:42 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:35:43 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:35:43 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 16:35:43 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.223219
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000368
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:35:43 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 16:35:43 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:215] Building idx file = /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv.idx
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:250] Time building 1 / 1 mem-mapped files: 0:00:00.218382
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000322
[NeMo I 2025-04-14 16:35:43 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:35:43 utils:73] Loading data from /workspace/zinc_example_data/test/
[NeMo W 2025-04-14 16:42:51 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:42:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:42:52 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:42:52 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:42:52 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:42:52 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: 4
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:42:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:42:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f864d1c49d0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f864d1c49d0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:42:52 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:42:52 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:42:52 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:42:52 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:42:52 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:42:52 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:42:52 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:42:52 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:42:52 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:42:52 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:42:52 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:42:52 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:42:52 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:42:52 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:42:52 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:42:52 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:42:52 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:42:52 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:42:52 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:42:52 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:42:52 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:42:52 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:42:52 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:42:52 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:42:52 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:42:52 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:42:52 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:42:52 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:42:52 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:42:53 finetune:105] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:107] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:42:53 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:42:53 finetune:111] ************** Starting Training ***********
[NeMo W 2025-04-14 16:42:53 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:42:53 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:42:53 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 16:42:53 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:215] Building idx file = /workspace/zinc_example_data/train/zinc_data_finetune_train.csv.idx
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:250] Time building 1 / 1 mem-mapped files: 0:00:00.236259
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000410
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:42:53 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 16:42:53 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:42:53 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:215] Building idx file = /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv.idx
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:250] Time building 1 / 1 mem-mapped files: 0:00:00.222538
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000316
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:42:54 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 16:42:54 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:215] Building idx file = /workspace/zinc_example_data/test/zinc_data_finetune_test.csv.idx
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:250] Time building 1 / 1 mem-mapped files: 0:00:00.236462
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000299
[NeMo I 2025-04-14 16:42:54 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:42:54 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 16:42:54 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 16:42:54 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 16:42:54 megamolbart_model:87] Finished building MegaMolBART datasets.
[NeMo W 2025-04-14 16:47:14 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:47:15 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:47:16 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:47:16 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:47:16 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:47:16 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: null
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:47:16 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:47:16 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7fe8acd16820> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7fe8acd16820>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:47:16 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:47:16 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:47:16 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:47:16 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:47:16 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:47:16 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:47:16 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:47:16 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:47:16 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:47:16 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:47:16 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:47:16 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:47:16 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:47:16 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:47:16 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:47:16 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:47:16 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:47:16 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:47:16 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:47:16 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:47:16 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:47:16 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:47:16 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:47:16 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:47:16 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:47:16 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:47:16 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:47:16 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:47:16 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:47:17 finetune:105] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:107] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:47:17 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:47:17 finetune:111] ************** Starting Training ***********
[NeMo W 2025-04-14 16:47:17 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:47:17 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:47:17 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 16:47:17 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.219052
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000349
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:47:17 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 16:47:17 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.227647
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000319
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:47:17 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 16:47:17 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:47:17 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:47:18 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.209229
[NeMo I 2025-04-14 16:47:18 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:47:18 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 16:47:18 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000299
[NeMo I 2025-04-14 16:47:18 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:47:18 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 16:47:18 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 16:47:18 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 16:47:18 megamolbart_model:87] Finished building MegaMolBART datasets.
[NeMo W 2025-04-14 16:48:49 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:48:50 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:48:50 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:48:50 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:48:50 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:48:50 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: null
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:48:50 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:48:50 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f6ccb0cd730> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f6ccb0cd730>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:48:50 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:48:50 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:48:50 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:48:50 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:48:50 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:48:50 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:48:51 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:48:51 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:48:51 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:48:51 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:48:51 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:48:51 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:48:51 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:48:51 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:48:51 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:48:51 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:48:51 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:48:51 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:48:51 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:48:51 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:48:51 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:48:51 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:48:51 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:48:51 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:48:51 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:48:51 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:48:51 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:48:51 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:48:51 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:48:51 finetune:105] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:107] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:48:51 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:48:51 finetune:111] ************** Starting Training ***********
[NeMo W 2025-04-14 16:48:51 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:48:51 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:48:51 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 16:48:51 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 16:48:51 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:48:51 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.235909
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000382
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:48:52 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 16:48:52 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.217062
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000765
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:48:52 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 16:48:52 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.232379
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000303
[NeMo I 2025-04-14 16:48:52 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:48:52 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 16:48:52 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 16:48:52 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 16:48:52 megamolbart_model:87] Finished building MegaMolBART datasets.
[NeMo W 2025-04-14 16:50:30 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:50:31 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:50:31 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:50:31 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:50:32 finetune:99] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:50:32 finetune:100] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: null
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:50:32 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:50:32 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f936274e9d0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f936274e9d0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:50:32 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:50:32 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:50:32 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:50:32 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:50:32 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:50:32 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:50:32 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:50:32 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:50:32 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:50:32 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:50:32 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:50:32 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:50:32 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:50:32 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:50:32 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:50:32 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:50:32 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:50:32 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:50:32 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:50:32 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:50:32 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:50:32 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:50:32 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:50:32 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:50:32 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:50:32 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:50:32 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:50:32 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:50:32 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:50:32 finetune:105] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:107] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:50:32 finetune:108] ***********************************************************
[NeMo I 2025-04-14 16:50:32 finetune:111] ************** Starting Training ***********
[NeMo W 2025-04-14 16:50:32 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:50:32 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:50:32 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 16:50:32 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 16:50:32 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:50:32 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.246549
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000372
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:50:33 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 16:50:33 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.254078
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000289
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:50:33 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 16:50:33 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.235844
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000291
[NeMo I 2025-04-14 16:50:33 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:50:33 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 16:50:33 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 16:50:33 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 16:50:33 megamolbart_model:87] Finished building MegaMolBART datasets.
[NeMo W 2025-04-14 16:54:57 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:54:58 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:54:58 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:54:58 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:54:58 finetune:102] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:54:58 finetune:103] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:54:58 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:54:58 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f49efc44820> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f49efc44820>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:54:58 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:54:59 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:54:59 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:54:59 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:54:59 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:54:59 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:54:59 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:54:59 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:54:59 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:54:59 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:54:59 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:54:59 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:54:59 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:54:59 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:54:59 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:54:59 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:54:59 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:54:59 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:54:59 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:54:59 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:54:59 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:54:59 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:54:59 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:54:59 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:54:59 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:54:59 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:54:59 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:54:59 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:54:59 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:54:59 finetune:108] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:110] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:54:59 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:54:59 finetune:114] ************** Starting Training ***********
[NeMo W 2025-04-14 16:54:59 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:54:59 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:54:59 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 16:54:59 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 16:54:59 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:54:59 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.238462
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000472
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:55:00 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 16:55:00 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.226124
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000377
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:55:00 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 16:55:00 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.231534
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000291
[NeMo I 2025-04-14 16:55:00 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:55:00 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 16:55:00 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 16:55:00 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 16:55:00 megamolbart_model:87] Finished building MegaMolBART datasets.
[NeMo W 2025-04-14 16:55:46 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:55:47 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:55:48 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:55:48 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:55:48 finetune:102] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:55:48 finetune:103] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: null
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:55:48 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:55:48 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f16ecb329d0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f16ecb329d0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:55:48 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:55:48 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:55:48 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:55:48 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:55:48 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:55:48 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:55:48 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:55:48 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:55:48 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:55:48 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:55:48 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:55:48 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:55:48 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:55:48 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:55:48 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:55:48 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:55:48 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:55:48 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:55:48 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:55:48 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:55:48 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:55:48 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:55:48 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:55:48 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:55:48 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:55:48 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:55:48 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:55:48 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:55:48 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:55:49 finetune:108] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:110] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:55:49 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:55:49 finetune:114] ************** Starting Training ***********
[NeMo W 2025-04-14 16:55:49 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:55:49 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:55:49 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 16:55:49 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.234073
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000363
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:55:49 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 16:55:49 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.239672
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000305
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:55:49 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 16:55:49 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:55:49 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:55:50 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.259099
[NeMo I 2025-04-14 16:55:50 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:55:50 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 16:55:50 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000311
[NeMo I 2025-04-14 16:55:50 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:55:50 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 16:55:50 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 16:55:50 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 16:55:50 megamolbart_model:87] Finished building MegaMolBART datasets.
[NeMo W 2025-04-14 16:59:09 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 16:59:10 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 16:59:11 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 16:59:11 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 16:59:11 finetune:102] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 16:59:11 finetune:103] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: null
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 16:59:11 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:59:11 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f58df78aaf0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f58df78aaf0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 16:59:11 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 16:59:11 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 16:59:11 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 16:59:11 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 16:59:11 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 16:59:11 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 16:59:11 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 16:59:11 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 16:59:11 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:59:11 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 16:59:11 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 16:59:11 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:59:11 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 16:59:11 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:59:11 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 16:59:11 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 16:59:11 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 16:59:11 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 16:59:11 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 16:59:11 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 16:59:11 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 16:59:11 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 16:59:11 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 16:59:11 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 16:59:11 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 16:59:11 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 16:59:11 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 16:59:11 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 16:59:11 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 16:59:11 finetune:108] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:110] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 16:59:11 finetune:111] ***********************************************************
[NeMo I 2025-04-14 16:59:11 finetune:114] ************** Starting Training ***********
[NeMo W 2025-04-14 16:59:11 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 16:59:12 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 16:59:12 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 16:59:12 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.235744
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000397
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:59:12 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 16:59:12 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.233573
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000305
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:59:12 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 16:59:12 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.243343
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000561
[NeMo I 2025-04-14 16:59:12 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 16:59:12 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 16:59:12 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 16:59:12 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 16:59:12 megamolbart_model:87] Finished building MegaMolBART datasets.
[NeMo W 2025-04-14 17:03:18 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 17:03:20 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 17:03:20 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 17:03:20 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 17:03:20 finetune:103] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 17:03:20 finetune:104] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: null
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 17:03:20 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 17:03:20 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f5335f4e910> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f5335f4e910>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 17:03:20 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 17:03:20 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 17:03:20 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 17:03:20 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 17:03:20 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 17:03:20 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 17:03:20 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 17:03:20 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 17:03:20 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:03:20 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 17:03:20 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 17:03:20 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:03:20 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 17:03:20 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:03:20 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 17:03:20 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 17:03:20 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 17:03:20 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:03:20 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 17:03:20 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 17:03:20 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 17:03:20 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 17:03:20 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 17:03:20 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 17:03:20 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 17:03:20 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 17:03:20 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 17:03:20 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 17:03:20 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 17:03:21 finetune:109] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:111] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 17:03:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:03:21 finetune:115] ************** Starting Training ***********
[NeMo W 2025-04-14 17:03:21 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 17:03:21 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 17:03:21 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 17:03:21 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 17:03:21 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 17:03:21 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 17:03:21 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.240792
[NeMo I 2025-04-14 17:03:21 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 17:03:21 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 17:03:21 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000374
[NeMo I 2025-04-14 17:03:21 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 17:03:21 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 17:03:21 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 17:03:21 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 17:03:21 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.230064
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000729
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 17:03:22 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 17:03:22 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.253319
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000302
[NeMo I 2025-04-14 17:03:22 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 17:03:22 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 17:03:22 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 17:03:22 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 17:03:22 megamolbart_model:87] Finished building MegaMolBART datasets.
[NeMo W 2025-04-14 17:05:18 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 17:05:19 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 17:05:20 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 17:05:20 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 17:05:20 finetune:103] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 17:05:20 finetune:104] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        num_workers: null
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 17:05:20 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 17:05:20 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f363884c9d0> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f363884c9d0>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 17:05:20 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 17:05:20 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 17:05:20 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 17:05:20 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 17:05:20 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 17:05:20 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 17:05:20 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 17:05:20 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 17:05:20 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:05:20 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 17:05:20 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 17:05:20 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:05:20 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 17:05:20 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:05:20 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 17:05:20 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 17:05:20 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 17:05:20 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:05:20 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 17:05:20 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 17:05:20 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 17:05:20 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 17:05:20 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 17:05:20 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 17:05:20 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 17:05:20 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 17:05:20 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 17:05:20 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 17:05:20 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 17:05:21 finetune:109] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:111] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 17:05:21 finetune:112] ***********************************************************
[NeMo I 2025-04-14 17:05:21 finetune:115] ************** Starting Training ***********
[NeMo W 2025-04-14 17:05:21 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 17:05:21 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 17:05:21 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 17:05:21 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.250933
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000926
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 17:05:21 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 17:05:21 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.229912
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000324
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 17:05:21 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 17:05:21 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.224485
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000726
[NeMo I 2025-04-14 17:05:21 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 17:05:21 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 17:05:21 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 17:05:21 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 17:05:21 megamolbart_model:87] Finished building MegaMolBART datasets.
[NeMo W 2025-04-14 17:07:30 optimizers:77] Could not import distributed_fused_adam optimizer from Apex
[NeMo W 2025-04-14 17:07:31 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
      warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
    
[NeMo W 2025-04-14 17:07:31 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2025-04-14 17:07:31 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo I 2025-04-14 17:07:31 finetune:105] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-04-14 17:07:31 finetune:106] 
    name: megamolbart_finetune
    do_training: true
    do_testing: false
    seed: 42
    restore_from_path: /tmp/models/MegaMolBART_0_2_0.nemo
    trainer:
      devices: 1
      num_nodes: 1
      precision: 16
      accelerator: gpu
      max_epochs: null
      max_steps: 1000
      log_every_n_steps: 10
      val_check_interval: 50
      limit_val_batches: 1
      limit_test_batches: 0
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      enable_checkpointing: false
      logger: false
      replace_sampler_ddp: false
    model:
      name: megamolbart_finetune_model
      global_batch_size: 8
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      resume_from_checkpoint: null
      pipeline_model_parallel_split_rank: 0
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      megatron_amp_O2: false
      seq_length: 512
      max_position_embeddings: 512
      num_layers: 3
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      attention_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      persist_layer_norm: true
      gradient_as_bucket_view: true
      bias_gelu_fusion: true
      masked_softmax_fusion: true
      bias_dropout_add_fusion: true
      bias: true
      normalization: layernorm
      encoder_arch: transformer
      decoder_arch: transformer
      activation: gelu
      headscale: false
      share_word_embeddings: true
      share_decoder_tokens_head_embeddings: false
      tokenizer:
        library: regex
        type: null
        model: /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
        vocab_file: /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
        merge_file: null
      data:
        dataset_path: /workspace/zinc_example_data
        dataset:
          train: zinc_data_finetune_train
          val: zinc_data_finetune_valid
          test: zinc_data_finetune_test
        newline_int: 10
        header_lines: 1
        data_col: 1
        data_sep: ','
        sort_dataset_paths: true
        skip_lines: 0
        micro_batch_size: 8
        encoder_augment: true
        encoder_mask: true
        decoder_augment: true
        decoder_mask: false
        canonicalize_input: true
        dataloader_type: single
        drop_last: false
        pin_memory: false
        links_file: null
        mask_scheme: span
        mask_prob: 0.15
        span_lambda: 3.0
        num_enumerations: 3
        dataset_format: csv
      optim:
        name: fused_adam
        lr: 1.0
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: NoamAnnealing
          d_model: 768
          warmup_steps: 100
          max_steps: 1000
          min_lr: 1.0e-05
    exp_manager:
      name: megamolbart_finetune
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 1
        monitor: val_molecular_accuracy
        mode: max
        save_last: true
        always_save_nemo: true
        filename: finetune--{val_molecular_accuracy:.2f}-{step}
        model_parallel_size: 1
      exp_dir: /workspace/results/finetune_logs
      create_tensorboard_logger: true
      create_wandb_logger: false
    
[NeMo W 2025-04-14 17:07:31 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ddp.DDPPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ddp.DDPStrategy` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 17:07:31 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f2d0e382850> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<nemo.collections.nlp.parts.nlp_overrides.NLPDDPPlugin object at 0x7f2d0e382850>)` instead.
      rank_zero_deprecation(
    
[NeMo W 2025-04-14 17:07:31 exp_manager:570] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
[NeMo W 2025-04-14 17:07:31 exp_manager:422] There was no checkpoint folder at checkpoint_dir :/workspace/results/finetune_logs/megamolbart_finetune/checkpoints. Training from scratch.
[NeMo I 2025-04-14 17:07:31 exp_manager:286] Experiments will be logged at /workspace/results/finetune_logs/megamolbart_finetune
[NeMo I 2025-04-14 17:07:31 exp_manager:660] TensorboardLogger has been set up
[NeMo W 2025-04-14 17:07:31 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.
      rank_zero_deprecation("`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.")
    
[NeMo W 2025-04-14 17:07:31 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 1000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2025-04-14 17:07:31 finetune:77] Resuming training from checkpoint: None
[NeMo I 2025-04-14 17:07:32 megatron_init:204] Rank 0 has data parallel group: [0]
[NeMo I 2025-04-14 17:07:32 megatron_init:207] All data parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:07:32 megatron_init:208] Ranks 0 has data parallel rank: 0
[NeMo I 2025-04-14 17:07:32 megatron_init:216] Rank 0 has model parallel group: [0]
[NeMo I 2025-04-14 17:07:32 megatron_init:217] All model parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:07:32 megatron_init:227] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-04-14 17:07:32 megatron_init:231] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:07:32 megatron_init:232] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-04-14 17:07:32 megatron_init:246] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-04-14 17:07:32 megatron_init:258] Rank 0 has embedding group: [0]
[NeMo I 2025-04-14 17:07:32 megatron_init:264] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-04-14 17:07:32 megatron_init:265] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-04-14 17:07:32 megatron_init:266] All embedding group ranks: [[0]]
[NeMo I 2025-04-14 17:07:32 megatron_init:267] Rank 0 has embedding rank: 0
[NeMo W 2025-04-14 17:07:32 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2025-04-14 17:07:32 tokenizer_utils:199] Using regex tokenization
[NeMo I 2025-04-14 17:07:32 regex_tokenizer:239] Loading vocabulary from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.vocab
[NeMo I 2025-04-14 17:07:32 regex_tokenizer:253] Loading regex from file = /opt/nvidia/nemo_chem/models/vocab/megamolbart.model
[NeMo I 2025-04-14 17:07:32 megatron_base_model:176] Padded vocab_size: 640, original vocab_size: 523, dummy tokens: 117.
[NeMo W 2025-04-14 17:07:32 megatron_lm_encoder_decoder_model:168] Could not find encoder or decoder in config. This is probably because of restoring an old checkpoint. Copying shared model configs to encoder and decoder configs.
[NeMo W 2025-04-14 17:07:32 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo W 2025-04-14 17:07:32 megatron_lm_encoder_decoder_model:140] bias_gelu_fusion is deprecated. Please use bias_activation_fusion instead.
[NeMo I 2025-04-14 17:07:32 finetune:111] ************** Model parameters and their sizes ***********
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.encoder_embedding.word_embeddings.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.encoder_embedding.position_embeddings.weight: torch.Size([512, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.encoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.0.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.1.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.input_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.weight: torch.Size([2304, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.query_key_value.bias: torch.Size([2304])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.self_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.query.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.weight: torch.Size([1536, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.key_value.bias: torch.Size([1536])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.weight: torch.Size([768, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.inter_attention.dense.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.post_inter_attention_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.weight: torch.Size([3072, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_h_to_4h.bias: torch.Size([3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.weight: torch.Size([768, 3072])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.layers.2.mlp.dense_4h_to_h.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.weight: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.enc_dec_model.decoder.model.final_layernorm.bias: torch.Size([768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:113] enc_dec_model.tokens_head.weight: torch.Size([640, 768])
[NeMo I 2025-04-14 17:07:32 finetune:114] ***********************************************************
[NeMo I 2025-04-14 17:07:32 finetune:117] ************** Starting Training ***********
[NeMo W 2025-04-14 17:07:32 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:317: LightningDeprecationWarning: The `LightningModule.on_pretrain_routine_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_fit_start` instead.
      rank_zero_deprecation(
    
[NeMo I 2025-04-14 17:07:32 megamolbart_model:61] Building MegaMolBART datasets.
[NeMo I 2025-04-14 17:07:32 utils:73] Loading data from /workspace/zinc_example_data/train/zinc_data_finetune_train
[NeMo I 2025-04-14 17:07:32 utils:77] Loading data from ['/workspace/zinc_example_data/train/zinc_data_finetune_train.csv']
[NeMo I 2025-04-14 17:07:32 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 17:07:32 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 17:07:32 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.223639
[NeMo I 2025-04-14 17:07:32 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 17:07:32 text_memmap_dataset:140] Loading /workspace/zinc_example_data/train/zinc_data_finetune_train.csv
[NeMo I 2025-04-14 17:07:32 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000385
[NeMo I 2025-04-14 17:07:32 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 17:07:32 utils:73] Loading data from /workspace/zinc_example_data/val/zinc_data_finetune_valid
[NeMo I 2025-04-14 17:07:32 utils:77] Loading data from ['/workspace/zinc_example_data/val/zinc_data_finetune_valid.csv']
[NeMo I 2025-04-14 17:07:32 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 17:07:32 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.221657
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:140] Loading /workspace/zinc_example_data/val/zinc_data_finetune_valid.csv
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000361
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 17:07:33 utils:73] Loading data from /workspace/zinc_example_data/test/zinc_data_finetune_test
[NeMo I 2025-04-14 17:07:33 utils:77] Loading data from ['/workspace/zinc_example_data/test/zinc_data_finetune_test.csv']
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:63] Building data files
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:244] Processing 1 data files using 10 workers
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:250] Time building 0 / 1 mem-mapped files: 0:00:00.215811
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:73] Loading data files
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:140] Loading /workspace/zinc_example_data/test/zinc_data_finetune_test.csv
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:76] Time loading 1 mem-mapped files: 0:00:00.000303
[NeMo I 2025-04-14 17:07:33 text_memmap_dataset:80] Computing global indices
[NeMo I 2025-04-14 17:07:33 megamolbart_model:84] Length of train dataset: 15062
[NeMo I 2025-04-14 17:07:33 megamolbart_model:85] Length of val dataset: 837
[NeMo I 2025-04-14 17:07:33 megamolbart_model:86] Length of test dataset: 837
[NeMo I 2025-04-14 17:07:33 megamolbart_model:87] Finished building MegaMolBART datasets.
